{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas & numpy library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# imoprt seaborn & matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import KNN from sklearn\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "# shows a bigger plot size for readability \n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "#improve resolution\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_218/3079004086.py:2: DtypeWarning: Columns (11,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  music = pd.read_csv('songDb.tsv', sep='\\t', encoding='ISO-8859-1')\n"
     ]
    }
   ],
   "source": [
    "# read 'songDb.tsv' into dataframe with correct encoding  \n",
    "music = pd.read_csv('songDb.tsv', sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Filtering rows\n",
    "- gets rid of NaN values\n",
    "- removes all songs that are not in the top 5 genres\n",
    "- fixes indexing \n",
    "- fixes dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alternativeamericana    1891\n",
       "electrolatino           1009\n",
       "doo-wop                  972\n",
       "reading                  969\n",
       "nuelectro                909\n",
       "                        ... \n",
       "azeripop                   2\n",
       "russianelectronic          2\n",
       "balticfolk                 1\n",
       "turkishhiphop              1\n",
       "modernperformance          1\n",
       "Name: Genre, Length: 625, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = music # for testing\n",
    "df['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = music # for testing\n",
    "\n",
    "df = df.rename({'Genre':'genres'}, axis='columns') # rename to match \n",
    "df = df.dropna()\n",
    "\n",
    "# combines subgenres into more general Genres. This function removes all genres outside of the top 5.\n",
    "# You can alter this to include more than the top 5 genres\n",
    "def CombineGenre(str_in):\n",
    "\n",
    "    try:\n",
    "        str_in = str_in.lower()\n",
    "        str_in = str_in.strip()\n",
    "        \n",
    "        if 'alternativeamericana' in str_in:\n",
    "            output = 'Alternative'\n",
    "        elif 'electrolatino' in str_in:\n",
    "            output = 'Electrolatino'\n",
    "        elif 'doo-wop' in str_in:\n",
    "            output = 'Doo-wop'\n",
    "        elif 'reading' in str_in:\n",
    "            output = 'Reading'\n",
    "        elif 'nuelectro' in str_in:\n",
    "            output = 'Nuelectro'\n",
    "        else:\n",
    "            output  = np.nan\n",
    "    except:\n",
    "        output = np.nan\n",
    "        \n",
    "    return output\n",
    "\n",
    "# applys above function to combine genres\n",
    "df['genres'] = df['genres'].apply(CombineGenre)\n",
    "df = df.dropna() # removes all genres that were not combined before \n",
    "df = df.reset_index() # resets the index since we removed many rows\n",
    "# df # shows now filtered df of music\n",
    "# df['genres'].value_counts() # shows number of songs in each top 5 genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Danceability', 'Energy', 'Key', 'Loudness', 'Mode',\n",
    "                'Speechness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence',\n",
    "                'Tempo', 'Duration_ms', 'time_signature']\n",
    "\n",
    "df[feature_cols] = df[feature_cols].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Design Matrix and Target vectors from the now filtered Df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature cols: ['Danceability', 'Energy', 'Key', 'Loudness', 'Mode', 'Speechness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms', 'time_signature']\n",
      "Target: genres\n"
     ]
    }
   ],
   "source": [
    "# Start by removing all columns that are not features \n",
    "\n",
    "feature_cols = ['Danceability', 'Energy', 'Key', 'Loudness', 'Mode',\n",
    "                'Speechness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence',\n",
    "                'Tempo', 'Duration_ms', 'time_signature']\n",
    "target_col = 'genres'\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "print(f'Feature cols: {feature_cols}')\n",
    "print(f'Target: {target_col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut down on dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut off dimensions to see affect on accuracy\n",
    "feature_cols = ['Danceability', 'Loudness',\n",
    "                'Speechness', 'Acousticness', 'Instrumentalness', 'Liveness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Sample the data to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a subset of the data 10% OR any other subset\n",
    "\n",
    "full_data = df[feature_cols + [target_col]]\n",
    "df_small = full_data.groupby('genres').apply(lambda x: x.sample(frac = 1, random_state = 0)).reset_index(\n",
    "    drop = True)\n",
    "\n",
    "\n",
    "# This is a small set for testing \n",
    "X_small = df_small[feature_cols]\n",
    "y_small = df_small[target_col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (4600, 6)\n",
      "Testing shape: (1150, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_small, y_small, stratify=y_small, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training shape: {X_train.shape}')\n",
    "print(f'Testing shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/neighbors/_nca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Call the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mopt_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptimizer_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Reshape the solution found by the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/neighbors/_nca.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[0;34m(self, transformation, X, same_class_mask, sign)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Compute softmax distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mp_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_diagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_ij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mp_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp_ij\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (n_samples, n_samples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1987\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    328\u001b[0m             )\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "# Label encoder for target (fitting it now to avoid unknown classes or different labels in testing)\n",
    "le = LabelEncoder().fit(df[target_col].unique())\n",
    "\n",
    "# KNN transformer and classifier\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=20, n_jobs = -1)  # default nn=20, testsize=0.1, frac=0.5, cut features set\n",
    "\n",
    "# Pipelining\n",
    "nca_pipe = Pipeline([\n",
    "    ('nca', nca), \n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "# Fit\n",
    "nca_pipe.fit(X_train, le.transform(y_train))\n",
    "\n",
    "# Preliminary score\n",
    "print(nca_pipe.score(X_test, le.transform(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6852173913043478"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM code linear\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "model = SVC(kernel='linear', C=50) # default linear            Note: testsize = 0.2, fract 0.99 we get 67.5% \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6678260869565218"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM code rbf\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "model = SVC(kernel='rbf', C=18)                    # \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "#cross_score = cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 316,
       "width": 741
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_results(gridsearchcv):\n",
    "    params = gridsearchcv.cv_results_[\"params\"]\n",
    "    ys = gridsearchcv.cv_results_[\"mean_test_score\"]\n",
    "    xs = ['|'.join(str(v) for v in param.values()) for param in params]\n",
    "    yerr = gridsearchcv.cv_results_[\"std_test_score\"]\n",
    "    plt.errorbar(xs, ys, yerr / np.sqrt(gridsearchcv.cv), fmt='.k')\n",
    "    plt.ylabel(\"f1\")\n",
    "    plt.xlabel(\"params\")\n",
    "    \n",
    "def check_for_convergence(gridsearchcv):\n",
    "    return gridsearchcv.best_estimator_.steps[-1][1].n_iter_ < gridsearchcv.best_estimator_.steps[-1][1].max_iter\n",
    "\n",
    "\n",
    "np.random.seed(31415) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "logistic = LogisticRegression() # first step\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"imputer\", imp), (\"logistic\", logistic)])\n",
    "\n",
    "# you don't need to modify the max_iter param. If you do, keep it under 1000\n",
    "# hint, prefix your param names with logistic__ to pass it to the logistic step\n",
    "\n",
    "# this grid when passed to the gridsearch will make a logistic regression \n",
    "# if you add more to the param_grid you can compare differnt models and see their IQR\n",
    "param_grid = { \n",
    "    \"logistic__C\" : 10.0 ** -np.arange(-2, 5),\n",
    "    \"logistic__solver\" : ['liblinear'], # use one algo from here it needs to be l1 https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "    \"logistic__penalty\" : ['l1'] # TA recommends using the l1 penalty \n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# use f1_micro for scoring\n",
    "# use 7 folds\n",
    "gscv = GridSearchCV(pipe, param_grid, scoring = 'f1_micro', cv=7) # GridSearchCV(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# gscv.fit(X_train, y_train)\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "plot_results(gscv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder().fit(df[target_col].unique())\n",
    "\n",
    "#Scale and convert data to np array\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train, y_train = np.array(X_train), np.array(le.transform(y_train))\n",
    "X_test, y_test = np.array(X_test), np.array(le.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Alternative',\n",
       " 1: 'Doo-wop',\n",
       " 2: 'Electrolatino',\n",
       " 3: 'Nuelectro',\n",
       " 4: 'Reading'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {i:le.inverse_transform([i])[0] for i in range(5)}\n",
    "#Label dictionary for confusion matrix\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset class to load in data into network\n",
    "class GenreDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Validation test to chec for overfitting\n",
    "X_train_s, X_val, y_train_s, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GenreDataset(torch.from_numpy(X_train_s).float(), torch.from_numpy(y_train_s).long())\n",
    "val_dataset = GenreDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
    "test_dataset = GenreDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize training parameters\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0007\n",
    "NUM_FEATURES = X_train.shape[1]\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Network\n",
    "\n",
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 512) \n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x) # 1st Layer \n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x) # ReLU Non Linearization\n",
    "        \n",
    "        x = self.layer_2(x) # 2nd Layer \n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x) # Dropout layer, randomly grops values for better accuracy\n",
    "        \n",
    "        x = self.layer_3(x) # 3rd layer\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x) # Output layer, will need to softmax while testing\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check and activate gpu\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification(\n",
      "  (layer_1): Linear(in_features=6, out_features=512, bias=True)\n",
      "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=5, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initalize Model and set optimizer and metric\n",
    "\n",
    "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Metric\n",
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries for plotting training curve\n",
    "\n",
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_218/2737581343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "    \n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "\n",
    "    print(\"Training...\")\n",
    "\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Feed model in batches\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_train_pred = model(X_train_batch)\n",
    "\n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "\n",
    "    print(\"Validating\")    \n",
    "    # VALIDATION    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        \n",
    "        #Stop training model and begin evaluation on validation set\n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "            y_val_pred = model(X_val_batch)\n",
    "                        \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "\n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "                                \n",
    "        \n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "train_val_acc_df = pd.DataFrame.from_dict(accuracy_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "train_val_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "# Plot the dataframes\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
    "sns.lineplot(data=train_val_acc_df, x = \"epochs\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\n",
    "sns.lineplot(data=train_val_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val Loss/Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on test set\n",
    "\n",
    "y_pred_list = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        _, y_pred_tags = torch.max(y_test_pred, dim = 1)\n",
    "        y_pred_list.append(y_pred_tags.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix of test set\n",
    "\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred_list)).rename(columns=label_dict, index=label_dict)\n",
    "\n",
    "sns.heatmap(confusion_matrix_df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics od model performance of each class \n",
    "\n",
    "print(classification_report(y_test, y_pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "66bd097daa38c52c1e4ae805b8855533c85460bc769a5080c99da237c2b318d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
