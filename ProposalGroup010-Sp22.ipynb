{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Group 10 Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- David Soberanis\n",
    "- Ernest Lin\n",
    "- Felipe Lorenzi\n",
    "- Shushruth Kallutla\n",
    "- John (Morgan) Harrison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "We intend to use songs' audio features to classify them into genres. Our features, provided by the Spotify API, include both low-level features (such as tempo, key, loudness), which are measured through signal processing methods on the audio tracks, and high-level features (such as danceability, valence, liveness), which are derived by Spotify from the low-level features using undisclosed methods. The genres of the songs are not provided by the Spotify API; rather, we will be using a dataset from Kaggle which contains the genres of many songs. In order to measure performance, we will be using Penn Machine Learning Benchmarks (PMLB), a collection of 42 well-tested datasets that can be used for benchmarking ML models, as well as confusion matrices and an F-1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "\n",
    "Musical genres are often umbrella terms which group songs with very distinct styles. However, some features, such as the rhythm, construction of the drum beat, instrumentation, presence of vocals, and others, can be useful for correctly classifying the genre of a song <a name=\"biss\"></a>[<sup>[1]</sup>](#bissnote). According to some, the classification of genres is often socially-driven, rather than based on the features of the songs themselves, placing songs into genres with the intention of targeting specific groups of listeners and making profit <a name=\"tagg\"></a>[<sup>[2]</sup>](#taggnote) <a name=\"greenberg\"></a>[<sup>[3]</sup>](#greenbergnote).\n",
    "\n",
    "However, relatively recent research uncovered that songs often cluster into three distinct categories: \"“Arousal” (the energy level of the music); “Valence” (the spectrum from sad to happy emotions in the music); and “Depth” (the amount of sophistication and emotional depth in the music)\" <a name=\"greenberg\"></a>[<sup>[3]</sup>](#greenbergnote).\n",
    "\n",
    "It would be interesting to understand if other musical features could be useful for classifying songs into genres. This could uncover new rule-sets for music genre recognition by analyzing which features are most associated with which genres. The features present in the Spotify API appear to be promising for this task as they include the features aforementioned of valence, arousal and depth and more. In addition, the Spotify API provides more low-level musical features which can be extracted from the audio signal of a song, and many examples can be found online of people classifying songs into genres based only on these low-level features, with some success <a name=\"venturott\"></a>[<sup>[4]</sup>](#venturottnote) <a name=\"elbir\"></a>[<sup>[5]</sup>](#elbirnote).\n",
    "\n",
    "Models for genre recognition could be useful for providing features to music recommendation systems, such as Spotify's itself. Furthermore, it is no news that knowing the genre of a song is useful for listeners to find songs they like, however having an automatic approach which only takes into account the actual musical features of a song could make the process faster and more fruitful to users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Our project aims to use supervised machine learning techniques to classify songs on Spotify into distinct Generes. By doing so, we hope to explore the underlying features that characterize each genere and the criterias that differentiate various generes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We shall source our data using a combination of prebuilt datasets on kaggle such as https://www.kaggle.com/datasets/naoh1092/spotify-genre-audio-features and custom built datasets using Spotify's public web API <a name=\"spotify\"></a>[<sup>[6]</sup>](#spotnote).\n",
    "\n",
    "We hope to obtain around 8000 songs from various genres. We will obtain the relevant Audio features<a name=\"spotify2\"></a>[<sup>[7]</sup>](#spot2note) and  Audio Analysis <a name=\"spotify3\"></a>[<sup>[8]</sup>](#spot3note) of each song.\n",
    "\n",
    "Audio Analysis records the physical musical features of a song such as rhythm, tempo, key. These variables are usualy numeric but can be categorical (such as key). Audio features are more abtract qualities such as dancebility, energy, acousticness and are derived from the Audio Analysis using the EchoNest Algorithm. These audio features are usually reprsented on a numeric scale from 0 to 1. We shall select the exact variables we want to explore after further discussion.\n",
    "\n",
    "We shall compile our custom datasets using Spotipy<a name=\"spotipy\"></a>[<sup>[8]</sup>](#spotipnote), a python library for the Spotify Web API. This tool will also be helpful in finding variables that are not recorded in our prebuilt datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "We will be utilizing supervised learning, with k-nearest neighbors. However, firstly, we must utilize a clustering optimization in order to find an optimal center of each grouping of songs, in order to find songs that exemplify genres. Songs can be organized into multiple clusters, using overlapping clustering, to showcase similar genres, and songs that blend multiple genres together, and fit not entirely within one. \n",
    "\n",
    "In using the k-nearest neighbor algorithm, along with density-based clustering, we can organize genres together loosely. We can then take these cluster’s data and determine what specific audio features are either necessary or prevalent within each genre cluster, along with determining good song recommendations nearby a user-liked song within it’s cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "- We will use Penn Machine Learning Benchmarks (PMLB) Which is a collection of 42 well-tested datasets that can be used for benchmarking both classification and regression supervised machine learning models<a name=\"PMLB\"></a>[<sup>[12]</sup>](#PMLB). \n",
    "- For classification accuracy, we will use a confusion matrix. A confusion matrix is used to evaluate the accuracy of a binary classifier model<a name=\"confusion matrix\"></a>[<sup>[10]</sup>](#confusionmatrix). Since we will be classifying songs by genres a confusion matrix will help us benchmark our classifier model. The way the confusion matrix works is one has predicted classes on the columns and actual classes on the rows. These predicted and actual classes are matched up for comparison. For example cell (1x1) could represent a true positive for the genre 'Rock' if the first row is an actual classification for 'Rock' and the first row is the predicted classification for 'Rock.' There are True Positives, True Negatives, False Positives, and False Negatives. Our data will include the genre of the songs which we will use for our (actual) classification in the matrix. After the confusion matrix is created we will calculate the accuracy of our model with the following:\n",
    "\n",
    "\\begin{align}\n",
    "        Accuracy = \\frac{TruePositive + TrueNegative \\ }{TotalSample}\n",
    "    \\end{align}\n",
    "- We can also test the sensitivity of our model with the following:\n",
    "\n",
    "\\begin{align}\n",
    "        True Positive Rate (Sensitivity) = \\frac{TruePositive \\ }{False Negative + True Positive}\n",
    "    \\end{align}\n",
    "\n",
    "- When we are deciding which classifier to use we can use an F1-Score for comparison. This test combines the precision and recall of a classifier into a single metric by using their harmonic mean. This will allow us to compare if classifier A has better recall or precision when compared to B then we can further test to see if precision is more important than recall or vice versa. \n",
    "- F1 score formula <a name=\"f1score\"></a>[<sup>[11]</sup>](#f1score)\n",
    "\n",
    "\\begin{align}\n",
    "        F1 = \\frac{2 \\ }{ \\frac{1}{Recall} + \\frac{1}{Precision}}\n",
    "    \\end{align}\n",
    "\n",
    "- Precision: Number of correct positives divided by the number of total positive results predicted by the classifier\n",
    "\n",
    "\\begin{align}\n",
    "        Precision = \\frac{TruePositive \\ }{True Positive + False Positive }\n",
    "    \\end{align}\n",
    "    \n",
    "- Recall: Number of correct positives divided by the number of all samples that should have been identified as positive \n",
    "\n",
    "\\begin{align}\n",
    "        Precision (Recall) = \\frac{TruePositive \\ }{True Positive + False Negative }\n",
    "    \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regards to data privacy, there is none to be concern about as the data we are going to use to train our models are simply song features, which are public information on Spotify provided by the Spotify API. Since these songs are available on Spotify, it means that the artists willingly published their songs to the public.\n",
    "\n",
    "One ethical concern with the datasets we will use is the possible biases. Since we cannot sample randomly from the set of every song in existence on Spotify, we have to resort to using sample datasets with songs that are mostly well known and popular. This might introduce bias into our data as there is a possibility that popular or well known songs share similar audio features. Less popular song genres may be excluded from the model's training dataset, which could have vastly different audio features. Additionally, there are numerous songs in different languages and cultures that public datasets may not cover. Songs with different cultural backgrounds may have vastly different features, and just analyzing popular songs in America is not representative of all the songs in the world. \n",
    "\n",
    "As such, our machine learning model may have more difficulty in identifying the correct valence for less well-known songs. One possible solution to this issue is to use a more diverse set of songs as our dataset, but from a realistic perspective it is impossible to sample from every form of music in existence. As such, the only solution is to address that the model we create can only be applied to popular or well-known songs of today in particularly the US."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Team Expectation 1*: meet once or twice a week\n",
    "* *Team Expectation 2*: try to meet on wed after class and 12 on Sat\n",
    "* *Team Expecation 3*: get assigned work done before next meeting\n",
    "* *Team Expecation 4*: 24-48 hours to respond to questions\n",
    "* *Team Expecation 5*: communicate on discord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/24  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 5/4  | 6 PM  | Import & Wrangle Data ,do some EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 5/11  | 12 PM  | Finalize wrangling/EDA; Begin programming for project | Discuss/edit project code; Complete project |\n",
    "| 5/25  | 12 PM  | Complete analysis; Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 6/8  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"bissnote\"></a>1.[^](#biss): Biss, Madars. (2021) Rhythm Tips for Identifying Music Genres by Ear. *Musical U*. https://www.musical-u.com/learn/rhythm-tips-for-identifying-music-genres-by-ear/<br> \n",
    "<a name=\"taggnote\"></a>2.[^](#tagg): Fabbri, Franco. (1980) A Theory of Musical Genres:\n",
    "Two Applications. *Popular Music Perspectives*. https://www.tagg.org/xpdfs/ffabbri81a.pdf<br> \n",
    "<a name=\"greenbergnote\"></a>3.[^](#greenberg): Greenberg, David M. (6, August 2016) Musical genres are out of date – but this new system explains why you might like both jazz and hip hop. *EconoTimes*. http://www.econotimes.com/Musical-genres-are-out-of-date-%E2%80%93-but-this-new-system-explains-why-you-might-like-both-jazz-and-hip-hop-244941<br> \n",
    "<a name=\"venturottnote\"></a>4.[^](#venturott): Venturott, Pedro H G. (31, January 2021) Predicting Music Genres Using Waveform Features. *Towards Data Science*. https://towardsdatascience.com/predicting-music-genres-using-waveform-features-5080e788eb64<br> \n",
    "<a name=\"elbirnote\"></a>5.[^](#elbir): Elbir, Ahmet et. al. (2018) Music Genre Classification and Recommendation by Using Machine Learning Techniques. *IEEE*. https://ieeexplore.ieee.org/document/8554016<br> \n",
    "<a name=\"spotify\"></a>6.[^](#spotnote): Spotify Web API. Spotify for Developers. (n.d.). Retrieved April 24, 2022, from https://developer.spotify.com/documentation/web-api/ <br>\n",
    "<a name=\"spotify2\"></a>7.[^](#spot2note): Web API reference: Get Audio Features. Get Track's Audio Features. (n.d.). Retrieved April 24, 2022, from https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features  <br>\n",
    "<a name=\"spotify3\"></a>8.[^](#spot3note): Web API reference: Get Audio Analysis. Get Track's Audio Analysis. (n.d.). Retrieved April 24, 2022, from https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-analysis  <br>\n",
    "<a name=\"spotipy\"></a>9.[^](#spotipnote): Paul Lamere, Spotipy, (2020), A light weight Python library for the Spotify Web API, https://github.com/plamere/spotipy\n",
    "<a name=\"confusion matrix\"></a>10.[^](#confusionmatrix): Bharathi, Analytics Vidhya, (2021), Confusion Matrix for Multi-Class Classification, https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/#h2_4  <br>\n",
    "<a name=\"f1score\"></a>11.[^](#f1score): Aditya Mishra, Towards Data Science, (2018), Metrics to Evaluate your Machine Learning Algorithm, https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234  <br>\n",
    "<a name=\"PMLB\"></a>12.[^](#PMLB): Penn Machine Learning Benchmarks (good data for testing our regression or classification models), https://epistasislab.github.io/pmlb/index.html  <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
